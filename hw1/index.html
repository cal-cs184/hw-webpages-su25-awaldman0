<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
			<h1>CS184/284A Spring 2025 Homework 1 Write-Up</h1>
			<div style="text-align: center;">Name: Alexander Waldman </div>

			<br>

			Link to webpage: <a href="https://cal-cs184.github.io/hw-webpages-su25-awaldman0/">cal-cs184.github.io/hw-webpages-su25-awaldman0</a>

			<br>

			Link to GitHub repository: <a href="https://github.com/cal-cs184/hw-webpages-su25-awaldman0">github.com/cal-cs184/hw-webpages-su25-awaldman0</a>

			<!--
	We've already added one heading per task, to make your write-up as navigable when grading. Please fit your write-up within these sections!
	-->

			<h2>Overview</h2>
			Give a high-level overview of what you implemented in this homework. Think about what you've built as a whole. Share your thoughts on what interesting things you've learned from completing the homework.

			<h2>Task 1: Drawing Single-Color Triangles</h2>
			When rasterizing triangles for this task, my goal was to take point data and appropriately translate it into graphical data that appears on screen. In doing so, I would use the color data passed into <code>RasterizerImp::rasterize_triangle()</code> to fill in
			the triangle I was working with. While rasterizing a single triangle does not look very impressive, repeated calls to the function allows me to display a great deal of triangles on screen, giving my rasterizer the ability to represent fairly intricate and
			complex geometry.

			In general, my triangle rasterization algorithm works by first sampling the center of each pixel within the bouding box of the triangle. If the center of the pixel lies in the triangle, I draw it to the screen.
			In detail, the algorithm works as follows:

			<ol>
				<li>
					When checking if a point lies within a triangle, my algorithm assumes the points <code>(x0, y0), (x1, y1),</code> and <code>(x2, y2)</code> are in counterclockwise winding order. Therefore, I need to ensure the x and y values passed into the function are in counterclockwise order by the time I do any bounds checking. I do this by creating two vectors, one between <code>(x0, y0)</code> and <code>(x1, y1)</code> and the other bewteen <code>(x1, y1)</code> and <code>(x2, y2)</code> and computing the cross product.
					If the cross product is negative, the point data is in clockwise order, in which case I swap the values of <code>(x1, y1) </code> and <code>(x2, y2)</code> to ensure a counterclockwise winding order.
				</li>
				<li>Define a vector for each side of the triangle and its corresponding normal vector</li>
				<li>Among the x and y values passed into the function, find the smallest and largest x and y values. Then take the <code>floor()</code> of those values and add 0.5, which gives us the coordinates of the center of each pixel that defines the triangle's bounding box.</li>
				<li>Iterate through each pixel in the bounding box, checking if the center of the current pixel is in the triangle by calculating the dot product of the vector bewteen the "first" point in each side of the triangle and the current coordinate with its cooresponding normal vector.</li>
				<li>If the current point lies on screen and he dot product is greater than or equal to 0 (to ensure we rasterize the edges in addition to interior points) for all three sides, then we draw it on screen.</li>
			</ol>

			My algorithm is no worse than one that checks each sample within the bounding box of the triangle (since that is exactly how it works), but it lacks certain optimizations that could improve performance like tiled triangle traversal.

			Pictured below is a <i>png</i> screenshot of my rasterizer displaying <i>basic/test4.svg</i> with the default viewing parameters with the pixel inspector hovering over an area close to the corner of a very thin triangle.

			<figure>
				<img src="./images/screenshot_7-7_20-5-30.png" alt="basic/test4.svg" style="width:400px" />
				<figcaption>Rasterization of <i>basic/test4.svg</i> without utilizing any antialiasing techniques.</figcaption>
			</figure>

			As you can see, our image is suffering from jaggies, and even leaves some pixels blank where the triangle does quite pass through the center of a pixel. This kind of aliasing is occuring because we only sample the <b>center</b> of each pixel when rasterizing, not allowing us to represent the geometry in an accurate or appealing way.


			<h2>Task 2: Antialiasing by Supersampling</h2>
			In order to remedy the aliasing seen in the screenshot from task 1, I implemented supersampling functionality into the rasterizer. Supersampling works by sampling multiple points <b>within</b> a single pixel and averaging out the results in order to determine a pixel's final color. This way, whether or not a triangle passes through the center of a pixel is no longer the sole factor when it comes to determining how a pixel is colored in. Supersampling is extremely helpful for getting rid of jaggies because it allows you to soften the edges of your geometry by blending edge pixels with those around them. When sampling, pixel/color data is initially stored in the <code>sample_buffer</code> vector before being finalized and put into <code>rgb_framebuffer_target</code> (which contains the data actually drawn to the screen). Since I need to store multiple samples per pixel and have to accomodate multiple potential sampling rates, I had to make some changes to the way my rasterizer manages memory to allow <code>sample_buffer</code> to be resized depending on the current sample rate.

			In order to implement supersampling and support multiple supersampling rates, I did the following:

			<ol>
				<li>
					In <code>RasterizerImp::set_sample_rate()</code>, I changed <code>this->sample_rate</code> to equal the rate passed into the fucntion and altered the call to <code>resize()</code> to scale the size of the vector by the rate passed into the function.
				</li>
				<li>
					In <code>RasterizerImp::set_framebuffer_target()</code>, I altered the call to <code>resize()</code> to scale the size of the vector by the rate passed into the function.
				</li>
				<li>
					I left <code>RasterizerImp::clear_buffers()</code> unchanged.
				</li>
			</ol>

			Next, I needed to actually implement supersampling functionality, which involved changing my implementation for <code>RasterizerImp::rasterize_triangle()</code> and <code>RasterizerImp::fill_pixel()</code>.

			<p>I made the following changes to <code>RasterizerImp::rasterize_triangle()</code>:</p>

			<ol>
				<li>
					Within the nested for loop used to iterate through each pixel in the triangle's bounding box, I added another nested for loop that would perform <code>sqrt(sample_rate) * sqrt(sample_rate)</code> samples at uniformally distributed locations within the current pixel.
				</li>
				<li>
					I defined a variable <i>offset</i> equal to <code>1 / sqrt(this->sample_rate)</code>.
				</li>
				<li>
					For pixel <code>(i, j)</code> and sub-pixel location <code>(k, l)</code> I sampled at <code>(i + (k * offset) + (offset / 2), j + (l * offset) + (offset / 2))</code>, which resulted in evenly distributed samples within the pixel.
				</li>
				<li>I performed the sample in-triangle tests as before, making sure to store the result at the proper index of <code>sample_buffer</code>, whose size changed depending on the sample rate</li>
			</ol>

			<p>Then, I altered <code>RasterizerImp::fill_pixel()</code> to set all of the indices corresponding to a particular pixel in <code>sample_buffer</code> to the same color so that the rasterizer could still render points and lines normally even after all of the samples within a pixel were averaged out.</p>

			<p>Finally, I changed <code>RasterizerImp::resolve_to_framebuffer()</code> such that for each pixel <code>(x, y)</code>, the function iterated through each sub-pixel sample, adding up the red, green, and blue componenets of the color stored at that location in <code>sample_buffer</code>. The function then divides the sums by the number of samples to obtain the average values of the red, green, and blue componenets of a particular pixel. Lastly, these average values are converted to 8-bit values and passed into <code>rgb_framebuffer_target</code>.</p>

			<p>The results of using supersampling in my rasterizer can be seen below, as the edges look much smoother when the sampling rate is higher. Supersampling helps the rasterizer perform much better when it comes to displaying very thin pieces of geometry, as it no longer leaves a pixel totally blank when a triangle does not happen to overlap with its center.</p>

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="./images/screenshot_7-8_18-23-37.png" width="400px" />
							<figcaption>Supersample rate 1 per pixel</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="./images/screenshot_7-8_18-23-39.png" width="400px" />
							<figcaption>Supersample rate 4 per pixel</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="./images/screenshot_7-8_18-23-41.png" width="400px" />
							<figcaption>Supersample rate 9 per pixel</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="./images/screenshot_7-8_18-23-43.png" width="400px" />
							<figcaption>Supersample rate 16 per pixel</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<h2>Task 3: Transforms</h2>
			After properly implementing transformations, I was able to employ scaling, translation, and rotation operations to alter <i>robot.svg</i> and create something new. I decided to try to make cubeman do some yoga, which I figured would require using all of the transformations I just coded in order to make the pose look right. The screenshot below depicts cubeman in tree pose, where you balance on one foot, plant your other foot on your standing leg and place your arms above your head to extend the body upwards.

			<figure>
				<img src="./images/screenshot_7-8_19-48-41.png" width="400px" />
				<figcaption>Cubeman doing yoga</figcaption>
			</figure>

			<h2>Task 4: Barycentric coordinates</h2>
			While having the ability to draw single-color triangles is nice, being able to represent a wide range of values (whether it be color data, texture data, normals, etc.) within a single triangle is very imporant in computer graphics. Up until now, my rasterizer was not equipped to handle that. I implemented this functionality by associating color data (in this case) with each vertex in a triangle and used interpolation to inform the rasterizer how to color all of the other pixels in the triangle. Smooth interpolation was achieved through the use of barycentric coordinates.

			In the barycentric coordinate system, each vertex in the triangle is associated with a point <code>(&alpha;, &beta;, &gamma;)</code>. Vertex A is located at <code>(1, 0, 0)</code>, vertex B is located at <code>(0, 1, 0)</code>, and vertex C is located at <code>(0, 0, 1)</code>. An arbitrary point <code>(&alpha;, &beta;, &gamma;)</code> represents a linear interpolation between all 3 vertices at once, and can be converted back to regular coordinates with the following formula: \( (x, y) = &alpha; * A + &beta; * B + &gamma; * C; \), where \( &alpha; + &beta; + &gamma; = 1 \).
			Likewise, we can use this formula to linearly interpolate color data associated with each vertex: \( C<sub>(x, y)</sub> = &alpha; * C<sub>A</sub> + &beta; * C<sub>B</sub> + &gamma; * C<sub>C</sub> \). Values for &alpha;, &beta;, and &gamma; can be derived using the positions of the vertices and the current position using the equations below.
			<figure>
				<img src="./images/formulas.png" width="600px" />
			</figure>

			All I needed to do was apply these formulas for every sample inside a given triangle, allowing me to represent color gradients. As a result, I was able to mostly reuse my implementation from Task 2, being sure to modify the code where I assign a color to the current location in <code>sample_buffer</code>.
			<figure>
				<img src="./images/screenshot_7-9_0-18-4.png" width="400px" />
				<figcaption>Triangle where vertices are colored red, green, and blue respectively</figcaption>
			</figure>
			The above image is a good example of how barycentric coordinates can be used to interpolate values within a triangle. When passing the data for this triangle into <code>rasterize_interpolated_color_triangle()</code>, only the vertices had any explicity defined color data, with vertex A, B, and C being colored red, green, and blue respectively. The color for every other pixel is some linear combination of the other three colors, and the use of barycentric coordinates allow for smooth interpolation between all three colors at once. After applying this concept to a single triangle, I was able to rasterize the image below, whose triangles corresponding color data combine to create a color wheel.

			<figure>
				<img src="./images/screenshot_7-9_0-17-51.png" width="400px" />
				<figcaption>Rasterization of <i>basic/test7.svg</i> with default viewing parameters and supersampling rate 1</figcaption>
			</figure>

			<h2>Task 5: "Pixel sampling" for texture mapping</h2>
			In computer graphics, pixel sampling involves getting color data for a specific pixel by sampling an image/texture at a position that properly cooresponds to the pixels position. When pixel sampling, one must convert between <code>(x, y)</code> position coordinates and <code>(u, v)</code>texture coordinates to ensure that we are sampling the texture at the correct location. In our case, each vertex of a particular triangle is associated with a <code>(u, v)</code> coordinate. It is our job to figure out where to sample the texture for the rest of the point in the triangle. As before, this requires interpolating bewteen the three <code>(u, v)</code> coordinates we are given, so I once again used barycentric coordinates for calculate the proper texture coordinates for each sample. As a result, my solution for this task looks extremely similar to my implementation for task 4. The code for <code>rasterize_textured_triangle</code> largely followed the structure of <code>rasterize_interpolated_color_triangle</code> with two key differences:

			<ol>
				<li>
					When swapping the values of <code>(x1, y1) </code> and <code>(x2, y2)</code> if vertices are passed into the fucntion in clockwise winding order, it is extremely important to also swap the values for <code>(u1, v1) </code> and <code>(u2, v2)</code>. If this is not done, the texture will be mirrored for triangles whose vertices were originally in clockwise winding order, leading to a very ugly "sharding" effect a textured image. Upon realizing this, I updated my implementation of <code>rasterize_interpolated_color_triangle</code> to properly swap colors around in the event of a clockwise winding order, as that would leading to similar errors that I was lucky enough to not run into yet.
				</li>
				<li>
					When assigning a color to the current sample, I needed to call either <code>sample_nearest</code> or <code>sample_bilinear</code> depending on the current pixel sampling mode.
				</li>
			</ol>

			This rasterizer supports two different ways of sampling pixels, nearest-neighbor and bilinear sampling. Since the mapping of screen-sapce to texture space is rarely 1:1 and we need to support things like sub-pixel sampling, <code>(u, v)</code> texture coordinates that we derive from screen-space positions are very unlikely to be whole numbers. We need whole numbers in order to get color data from the <code>texels</code> vector, however, so we need to find a way to convert our floating point <code>(u, v)</code> values to color data. The first method, which I implemented in <code>sample_nearest</code> simply rounds u and v to the closest whole number and uses them to sample from the texture. This works, but it can lead to a more pixelated look in the final image. The other method, which I implemented in <code>sample_linear</code>, first samples the four texels <b>closest</b> to u and v before performing a series of linear interpolations to determine the appropriate color at <code>(u, v)</code>. While more computationally expensive, this results in a smoother image than nearest neighbor pixel sampling.
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="./images/screenshot_7-10_0-41-0.png" width="400px" />
							<figcaption>Swirled Cal seal with nearest-pixel sampling</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="./images/screenshot_7-10_0-41-1.png" width="400px" />
							<figcaption>Swirled Cal seal with bilinear sampling</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<p>The difference between the two pixel sampling methods is extremely apparant in the images above. Bilinear sampling is clearly preferable in this case, as it makes the text on the seal much more legible by smoothing out color differences. </p>

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="./images/screenshot_7-10_0-35-38.png" width="750px" />
							<figcaption>Nearest sampling at 1 sample per pixel</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="./images/screenshot_7-10_0-35-46.png" width="750px" />
							<figcaption>Nearest sampling at 16 samples per pixel</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="./images/screenshot_7-10_0-36-13.png" width="750px" />
							<figcaption>Bilinear sampling at 1 sample per pixel</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="./images/screenshot_7-10_0-36-21.png" width="750px" />
							<figcaption>Bilinear sampling at 16 samples per pixel</figcaption>
						</td>
					</tr>
				</table>
			</div>
			Pictured above is four copies of the same image using different pixel sampling methods and supersampling rates. AT 1 sample per pixel, the differences between nearest-neighbor and bilinear pixel sampling aren't too hard to spot, espectially if you zoom in on the left edge of the campinele. When we increase the number of samples per pixel to 16, however, the difference is nearly imperceptible (even under the pixel inspector), going to show how using a more computationally expensive and "better" pixel sampling method does not always result in noticeably higher quality image. This means that, in certain situations, bilinear pixel sampling may not be worth it over simpler, less precise approaches to texture sampling.


			<h2>Task 6: "Level Sampling" with mipmaps for texture mapping</h2>
			Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

			<h2>(Optional) Task 7: Extra Credit - Draw Something Creative!</h2>
			Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
		</div>
	</body>
</html>
